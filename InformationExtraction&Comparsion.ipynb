{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JErry453/InformationExtraction-Comparsion-Ml-Project/blob/main/InformationExtraction%26Comparsion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G_yRJf1tyuZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1e2688-73de-4e72-c91a-5596718e1f2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "nlp=spacy.load(\"en_core_web_sm\")\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import Counter\n",
        "import nltk\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "import sys\n",
        "np.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre Processing the Text: Tokenization,Lemmatization,Removing StopWords**"
      ],
      "metadata": {
        "id": "O3IkBRaXZ7av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preProcess(paragraph):\n",
        "  doc=nlp(paragraph)\n",
        "  processed_sentences=[]\n",
        "  for sentence in doc.sents:\n",
        "    tokens=[token.lemma_.lower() for token in sentence if not token.is_stop and not token.is_punct and not token.is_space]\n",
        "    processed_sentence=\" \".join(tokens)\n",
        "    processed_sentences.append(processed_sentence)\n",
        "  return processed_sentences"
      ],
      "metadata": {
        "id": "FfAPvahW9FEA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finding Number Of Sentences in Given**"
      ],
      "metadata": {
        "id": "JxE7XREQeNuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findNumberOfSentences(text):\n",
        "   doc = nlp(text)\n",
        "   num_sentences = len(list(doc.sents))\n",
        "   return num_sentences"
      ],
      "metadata": {
        "id": "nM6WPcBZZj7J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Checking whether a Sentence Has Numerical Data or not**"
      ],
      "metadata": {
        "id": "x2OmbAadeZfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def checkNumerical(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    for token in doc:\n",
        "        if token.like_num:\n",
        "            try:                #for avoiding figures like million,billion etc.\n",
        "                a=float(token.text)\n",
        "                return 1\n",
        "            except ValueError:\n",
        "                pass\n",
        "    return 0"
      ],
      "metadata": {
        "id": "LjyA8VSYdnWJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def containNumerical_data(text):\n",
        "  arr=[]\n",
        "  for sentence in text:\n",
        "    has_numerical=checkNumerical(sentence)\n",
        "    arr.append(has_numerical)\n",
        "  return arr"
      ],
      "metadata": {
        "id": "7LKwYZMEaqZm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Matrix for Similar Sentences in Both Paragraphs**"
      ],
      "metadata": {
        "id": "j_Jw-321rdXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_similarity(sentence1,sentence2):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([sentence1, sentence2])\n",
        "    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "    return similarity[0][0]"
      ],
      "metadata": {
        "id": "lOA6IyHojYf1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def comparing_sentences(sentences1,sentences2):\n",
        "    similarity_matrix = np.zeros((len(sentences2), len(sentences1)))\n",
        "    for i, sentence1 in enumerate(sentences1):\n",
        "        for j, sentence2 in enumerate(sentences2):\n",
        "            similarity_score = check_similarity(sentence1, sentence2)\n",
        "            similarity_matrix[j][i] = similarity_score\n",
        "\n",
        "    for i in range(len(sentences2)):\n",
        "        max_similarity_index = np.argmax(similarity_matrix[i])\n",
        "        max_similarity_score = similarity_matrix[i][max_similarity_index]\n",
        "        similarity_matrix[i] = 0\n",
        "        similarity_matrix[i][max_similarity_index] = max_similarity_score\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "id": "bn2nCkPvej6d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting the Major attribute of each sentence**"
      ],
      "metadata": {
        "id": "oMfhDVRKxvh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    keywords = []\n",
        "    for token in doc:\n",
        "        if token.pos_ in ['NOUN', 'PROPN', 'ADJ']:\n",
        "            keywords.append(token.text)\n",
        "    return keywords"
      ],
      "metadata": {
        "id": "mbgIumPg9DJK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_context(sentence1,sentence2):\n",
        "  keywords1=extract_keywords(sentence1)\n",
        "  keywords2=extract_keywords(sentence2)\n",
        "\n",
        "  common_keywords=set(keywords1).intersection(keywords2)\n",
        "\n",
        "  if common_keywords:\n",
        "    keyword_counts = Counter(common_keywords)\n",
        "    return max(keyword_counts, key=keyword_counts.get)\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "R0NMZDnx96Y_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sentiment Analysis**"
      ],
      "metadata": {
        "id": "RmUYNU_Y2g4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_score(sentence):\n",
        "    sentiment_score = sid.polarity_scores(sentence)\n",
        "    return sentiment_score['compound']"
      ],
      "metadata": {
        "id": "WdMW-JwX-h_4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_sentences(sentence1, sentence2):\n",
        "    sentiment_score1 = get_sentiment_score(sentence1)\n",
        "    sentiment_score2 = get_sentiment_score(sentence2)\n",
        "\n",
        "    if sentiment_score1 > sentiment_score2:\n",
        "        return 1\n",
        "    elif sentiment_score1 < sentiment_score2:\n",
        "        return -1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "gM9PfiaezMZa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparing Numerical Values**"
      ],
      "metadata": {
        "id": "43XukIENYUcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_numerical_values(sentence):\n",
        "    doc = nlp(sentence)\n",
        "    numerical_values = []\n",
        "    for token in doc:\n",
        "        if token.pos_ == 'NUM':\n",
        "            try:\n",
        "                numerical_values.append(float(token.text))\n",
        "            except ValueError:\n",
        "                pass\n",
        "    return max(numerical_values)"
      ],
      "metadata": {
        "id": "32q7RAuEojpd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_numerical_values(sentence1, sentence2):\n",
        "    values1 = extract_numerical_values(sentence1)\n",
        "    values2 = extract_numerical_values(sentence2)\n",
        "\n",
        "    if not values1 or not values2:\n",
        "        return \"No numerical values found in one or both sentences\"\n",
        "\n",
        "    max_value1 = values1\n",
        "    max_value2 = values2\n",
        "\n",
        "    if max_value1 == max_value2:\n",
        "        return \"0\"\n",
        "    elif max_value1 > max_value2:\n",
        "        return \"1\"\n",
        "    else:\n",
        "        return \"-1\"\n"
      ],
      "metadata": {
        "id": "kdJFkT_xomJu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1=\"Apple Inc. is a multinational technology company headquartered in Cupertino, California.Ram is a 5 good boy.Ram got 30 marks in maths test.\"\n",
        "s2=\"Tellicus Inc. is a national technology company headquartered in Delhi,India.Shyam is an average boy.Shyam got 32 marks in maths test.\"\n",
        "t1=preProcess(s1)\n",
        "a1=sum(containNumerical_data(t1))\n",
        "print(a1)\n",
        "t2=preProcess(s2)\n",
        "a2=containNumerical_data(t2)\n",
        "print(a2)\n",
        "matrix=comparing_sentences(t1,t2)\n",
        "for row in matrix:\n",
        "        print(row)\n",
        "sentences1=t1[0]\n",
        "sentences2=t2[0]\n",
        "for i in range(min(len(sentences1), len(sentences2))):\n",
        "    sentence1 = sentences1[i]\n",
        "    sentence2 = sentences2[i]\n",
        "print(f\"Common subject in sentences {i+1}: {determine_context(t1[0],t2[0])}\")\n",
        "print(compare_sentences(t1[1], t2[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0neLqjTt9_Ag",
        "outputId": "8b528a32-97e2-4023-a69e-443194825401"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "[0, 0, 1]\n",
            "[0.33609693 0.         0.        ]\n",
            "[0.         0.20199309 0.        ]\n",
            "[0.         0.         0.50310261]\n",
            "Common subject in sentences 65: technology\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from types import prepare_class\n",
        "def main(p1,p2):\n",
        "  processedP1=preProcess(p1)\n",
        "  processedP2=preProcess(p2)\n",
        "  matrix2d=comparing_sentences(processedP1,processedP2)\n",
        "  isNum1=containNumerical_data(processedP1)\n",
        "  isNum2=containNumerical_data(processedP2)\n",
        "  rows=np.count_nonzero(matrix2d)+2\n",
        "  columns=4\n",
        "  print(\"Sentence_Similarity_Matrix\")\n",
        "  print(matrix2d)\n",
        "  finalMatrix=np.empty((rows,columns),dtype=np.dtype('U50'))\n",
        "  finalMatrix[0][1]=\"Text1\"\n",
        "  finalMatrix[0][2]=\"Text2\"\n",
        "  finalMatrix[0][3]=\"Output\"\n",
        "  finalMatrix[rows-1][0]=\"Total\"\n",
        "\n",
        "  for i in range(0,rows-2):\n",
        "    for j in range(0,findNumberOfSentences(p1)):\n",
        "      if matrix2d[i][j]!=0:\n",
        "        common_keyword=determine_context(processedP2[i],processedP1[j])\n",
        "        finalMatrix[i+1][0]=common_keyword\n",
        "        if isNum1[j]!=0 and isNum2[i]!=0:\n",
        "          if get_sentiment_score(processedP1[j])>0 and get_sentiment_score(processedP2[i])>0:\n",
        "            finalMatrix[i+1][1]=extract_numerical_values(processedP1[j])\n",
        "            finalMatrix[i+1][2]=extract_numerical_values(processedP2[i])\n",
        "            finalMatrix[i+1][3]=compare_numerical_values(processedP1[j],processedP2[i])\n",
        "          elif get_sentiment_score(processedP1[j])>0 and get_sentiment_score(processedP2[i])<0:\n",
        "            finalMatrix[i+1][1]=extract_numerical_values(processedP1[j])\n",
        "            finalMatrix[i+1][2]=extract_numerical_values(processedP2[i])\n",
        "            finalMatrix[i+1][3]=\"1\"\n",
        "          elif get_sentiment_score(processedP1[j])<0 and get_sentiment_score(processedP2[i])>0:\n",
        "            finalMatrix[i+1][1]=extract_numerical_values(processedP1[j])\n",
        "            finalMatrix[i+1][2]=extract_numerical_values(processedP2[i])\n",
        "            finalMatrix[i+1][3]=\"-1\"\n",
        "          else:\n",
        "            finalMatrix[i+1][1]=extract_numerical_values(processedP1[j])\n",
        "            finalMatrix[i+1][2]=extract_numerical_values(processedP2[i])\n",
        "            finalMatrix[i+1][3]=-1*int(compare_numerical_values(processedP1[j],processedP2[i]))\n",
        "        else:\n",
        "          finalMatrix[i+1][1]=get_sentiment_score(processedP1[j])\n",
        "          finalMatrix[i+1][2]=get_sentiment_score(processedP2[i])\n",
        "          finalMatrix[i+1][3]=compare_sentences(processedP1[j],processedP2[i])\n",
        "  sum=0\n",
        "  for i in range(1,rows-1):\n",
        "    sum=sum+int(finalMatrix[i][columns-1])\n",
        "  finalMatrix[rows-1][columns-1]=sum\n",
        "\n",
        "\n",
        "\n",
        "  print(\"Final_Matrix:-\")\n",
        "  for row in finalMatrix:\n",
        "    print(\"[\", end=\"\")\n",
        "    for element in row:\n",
        "        print(f\"{element:10}\", end=\" \")\n",
        "    print(\"]\")\n",
        "\n",
        "#Printing Final descision\n",
        "  if finalMatrix[rows-1][columns-1]>\"0\":\n",
        "      print(\"Entity in Text 1 is better than Entity in Text 2 \")\n",
        "  elif finalMatrix[rows-1][columns-1]<\"0\":\n",
        "      print(\"Entity in Text 2 is better than Entity in Text 1 \")\n",
        "  else:\n",
        "      print(\"Entity in Text 1 is equal to Entity in Text 2 \")\n",
        "\n",
        "\n",
        "\n",
        "t1='''Modi increased the education budget by 20%. It resulted in the construction of 25 new schools.\n",
        " Modi also implemented a scholarship program for underprivileged students, which helped 10000 children attend school.\n",
        " Additionally, Modi's reforms in the education sector led to a 10% increase in the literacy rate.\n",
        " Modi decreased health facility by 15%.'''\n",
        "t2='''Gandhi introduced a new Education budget with the increase of 10%.\n",
        "Gandhi led many developments including the construction of 100 new schools.\n",
        "These projects led to 100000 underprivelidged Children going to schools.\n",
        "Gandhi's efforts in improving number of schools also resulted in a 20% decrease in Literacy rate.\n",
        "Gandhi increased health facility by 10%.'''\n",
        "\n",
        "main(t1,t2)\n",
        "\n"
      ],
      "metadata": {
        "id": "75weDIdz5yqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6717336a-6abf-406e-c9ad-4b73a0c1e14c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence_Similarity_Matrix\n",
            "[[0.34464214 0.         0.         0.         0.        ]\n",
            " [0.         0.31710747 0.         0.         0.        ]\n",
            " [0.         0.         0.13049436 0.         0.        ]\n",
            " [0.         0.16836842 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.2523342 ]]\n",
            "Final_Matrix:-\n",
            "[           Text1      Text2      Output     ]\n",
            "[education  20.0       10.0       1          ]\n",
            "[new        25.0       100.0      1          ]\n",
            "[child      10000.0    100000.0   1          ]\n",
            "[school     25.0       20.0       -1         ]\n",
            "[facility   15.0       10.0       -1         ]\n",
            "[Total                            1          ]\n",
            "Entity in Text 1 is better than Entity in Text 2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q1='''Raman is a good boy.Raman got 25 marks in Maths by using unfair means.\n",
        "Raman always help his mother in her work.He smokes 2 cigrattes in a day which is bad for his health.'''\n",
        "q2='''Pathak is a bad boy.He eat 2 apple daily for better health.\n",
        "Pathak got 23 marks in Maths by his own hardwork.Pathak never helps his mother ,infact create trouble for her.'''\n",
        "main(q1,q2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xUMKX0QnHo-",
        "outputId": "565a24a5-2f43-4fd5-b6ce-06325ae8fb9e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence_Similarity_Matrix\n",
            "[[0.20199309 0.         0.         0.        ]\n",
            " [0.         0.         0.         0.11234278]\n",
            " [0.         0.30412574 0.         0.        ]\n",
            " [0.         0.         0.26055567 0.        ]]\n",
            "Final_Matrix:-\n",
            "[           Text1      Text2      Output     ]\n",
            "[boy        0.4404     -0.5423    1          ]\n",
            "[health     2.0        2.0        -1         ]\n",
            "[maths      25.0       23.0       -1         ]\n",
            "[mother     0.4019     0.2732     1          ]\n",
            "[Total                            0          ]\n",
            "Entity in Text 1 is equal to Entity in Text 2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1='''Ram was king of Ayodhya.He always obeyed is father.He killed 10000 demons to save mankind.He respected women.\n",
        "     Ram was the symbol of discipline.He got 14 years of vanvaas from his father.Ram was a devotee of lord Shiva'''\n",
        "w2='''Ravan was king of Lanka.He never respect women.He  never obeyed his father.Ravan was the biggest devotee of Lord Shiva.\n",
        "      He has 100000 demons in his army to destroy mankind.Ravan was the symbol of Arrogance.'''\n",
        "main(w1,w2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYwaxeVpqf_o",
        "outputId": "7847ecfb-ef8c-4b43-8210-54ab0137ff4f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence_Similarity_Matrix\n",
            "[[0.20199309 0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         1.         0.         0.\n",
            "  0.        ]\n",
            " [0.         1.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.51014902]\n",
            " [0.         0.         0.2523342  0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.20199309 0.\n",
            "  0.        ]]\n",
            "Final_Matrix:-\n",
            "[           Text1      Text2      Output     ]\n",
            "[king       0.0        0.0        0          ]\n",
            "[respect    0.4767     0.4767     0          ]\n",
            "[father     0.0        0.0        0          ]\n",
            "[shiva      0.3818     0.3818     0          ]\n",
            "[demon      10000.0    100000.0   1          ]\n",
            "[symbol     0.0        -0.5267    1          ]\n",
            "[Total                            2          ]\n",
            "Entity in Text 1 is better than Entity in Text 2 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "GqE5DfS8mHas"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('nlp_model.pkl', 'wb') as file:\n",
        "    pickle.dump(main, file)"
      ],
      "metadata": {
        "id": "KewZ0hF8qNPH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('nlp_model.pkl', 'rb') as file:\n",
        "    loaded_main_function = pickle.load(file)"
      ],
      "metadata": {
        "id": "gmiq45Wnqa5l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_main_function(w1,w2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqYriZFsqhpy",
        "outputId": "0547837d-c3e1-4ae0-c3ad-6f683c78b573"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence_Similarity_Matrix\n",
            "[[0.20199309 0.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         1.         0.         0.\n",
            "  0.        ]\n",
            " [0.         1.         0.         0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.51014902]\n",
            " [0.         0.         0.2523342  0.         0.         0.\n",
            "  0.        ]\n",
            " [0.         0.         0.         0.         0.20199309 0.\n",
            "  0.        ]]\n",
            "Final_Matrix:-\n",
            "[           Text1      Text2      Output     ]\n",
            "[king       0.0        0.0        0          ]\n",
            "[respect    0.4767     0.4767     0          ]\n",
            "[father     0.0        0.0        0          ]\n",
            "[shiva      0.3818     0.3818     0          ]\n",
            "[demon      10000.0    100000.0   1          ]\n",
            "[symbol     0.0        -0.5267    1          ]\n",
            "[Total                            2          ]\n",
            "Entity in Text 1 is better than Entity in Text 2 \n"
          ]
        }
      ]
    }
  ]
}